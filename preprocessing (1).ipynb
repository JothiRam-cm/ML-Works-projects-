{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ccb9a83-5a04-4329-8100-72fde5200fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrupted image files: []\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def find_corrupted_images(folder_path):\n",
    "    # Get list of files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "    corrupted_images = []\n",
    "\n",
    "    # Check each file if it's an image and if it's corrupted\n",
    "    for file in files:\n",
    "        try:\n",
    "            image_path = os.path.join(folder_path, file)\n",
    "            with Image.open(image_path) as img:\n",
    "                img.verify()  # Verify if the image file is valid\n",
    "        except (IOError, SyntaxError) as e:\n",
    "            corrupted_images.append(file)\n",
    "\n",
    "    return corrupted_images\n",
    "\n",
    "# Example usage:\n",
    "folder_path = r\"D:\\company\\archive\\Dataset\\val\\reusable\"\n",
    "corrupted_images = find_corrupted_images(folder_path)\n",
    "\n",
    "# Store the names of corrupted images in a variable\n",
    "corrupted_images_names = []\n",
    "for image in corrupted_images:\n",
    "    corrupted_images_names.append(image)\n",
    "\n",
    "# Now you can use the variable corrupted_images_names as needed\n",
    "print(\"Corrupted image files:\",corrupted_images_names )\n",
    "for image_name in corrupted_images_names:\n",
    "    print(image_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "773b6db6-31de-4a2b-a38c-57bc54ef8d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# folder_path = r\"D:\\company\\e-waste\\training\\Non-reusable\"\n",
    "# file_names = corrupted_images_names\n",
    "def delete_files_with_names(folder_path, file_names):\n",
    "    # Get list of files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    # Iterate through files and delete those with specified names\n",
    "    for file in files:\n",
    "        if file in file_names:\n",
    "            os.remove(os.path.join(folder_path, file))\n",
    "            print(f\"Deleted file: {file}\")\n",
    "\n",
    "# Example usage:\n",
    "folder_path = r\"D:\\company\\e-waste\\validation\\Reusable\"\n",
    "names_to_delete = corrupted_images_names  # Add names of files to delete\n",
    "delete_files_with_names(folder_path, names_to_delete)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13f3dee2-e4c6-4c8a-9464-8a7780a6af33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def rename_files_with_count(folder_path):\n",
    "    # Get list of files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    # Dictionary to store count of each file extension\n",
    "    file_count = {}\n",
    "\n",
    "    # Count occurrences of each file extension\n",
    "    for file in files:\n",
    "        _, ext = os.path.splitext(file)\n",
    "        if ext in file_count:\n",
    "            file_count[ext] += 1\n",
    "        else:\n",
    "            file_count[ext] = 1\n",
    "\n",
    "    # Rename files with count\n",
    "    for file in files:\n",
    "        _, ext = os.path.splitext(file)\n",
    "        count = file_count[ext]\n",
    "        new_name = f\"{count}{ext}\"\n",
    "        while os.path.exists(os.path.join(folder_path, new_name)):\n",
    "            count += 1\n",
    "            new_name = f\"{count}{ext}\"\n",
    "        os.rename(os.path.join(folder_path, file), os.path.join(folder_path, new_name))\n",
    "        file_count[ext] -= 1\n",
    "\n",
    "# Example usage:\n",
    "folder_path = r\"D:\\company\\archive\\Dataset\\val\\reusable\"\n",
    "rename_files_with_count(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9ae5848-be19-4827-8322-3fc3b4e0fe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def remove_corrupted_images(folder_path):\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"The folder '{folder_path}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    # Get a list of all files in the directory\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    # Iterate through each file\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        # Check if it's a file\n",
    "        if os.path.isfile(file_path):\n",
    "            try:\n",
    "                # Attempt to open the image\n",
    "                img = Image.open(file_path)\n",
    "                img.verify()  # Verify image file integrity\n",
    "            except (IOError, SyntaxError) as e:\n",
    "                print(f\"Removing corrupted image: {file}\")\n",
    "                os.remove(file_path)\n",
    "\n",
    "# Example usage\n",
    "dataset_folder = r\"D:\\company\\e-waste\\training\\Reusable\"\n",
    "remove_corrupted_images(dataset_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4ebcf95-5b67-4b60-bec3-513e8d90a471",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "image file is truncated (3 bytes not processed)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m input_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcompany\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124me-waste\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mReusable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m output_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreusable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 29\u001b[0m \u001b[43mresize_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Define the directory where you want to save the dataset\u001b[39;00m\n\u001b[0;32m     33\u001b[0m save_dir \u001b[38;5;241m=\u001b[39m output_directory\n",
      "Cell \u001b[1;32mIn[5], line 21\u001b[0m, in \u001b[0;36mresize_images\u001b[1;34m(input_dir, output_dir, target_size)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.bmp\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jfif\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mopen(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_dir, filename)) \u001b[38;5;28;01mas\u001b[39;00m img:\n\u001b[1;32m---> 21\u001b[0m             resized_img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m             resized_img\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, filename))\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage resizing completed successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\PIL\\Image.py:2164\u001b[0m, in \u001b[0;36mImage.resize\u001b[1;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[0;32m   2160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   2162\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(size)\n\u001b[1;32m-> 2164\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m box \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2166\u001b[0m     box \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\PIL\\ImageFile.py:288\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    284\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    285\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage file is truncated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(b)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m bytes not processed)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m         )\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    290\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m    291\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(b)\n",
      "\u001b[1;31mOSError\u001b[0m: image file is truncated (3 bytes not processed)"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np  # Add this import statement\n",
    "from PIL import Image, ImageOps  # Import ImageOps module\n",
    "\n",
    "def resize_images(input_dir, output_dir, target_size=(150, 150)):\n",
    "    \"\"\"\n",
    "    Resize images in the input directory and save them to the output directory.\n",
    "\n",
    "    Parameters:\n",
    "        input_dir (str): Path to the directory containing input images.\n",
    "        output_dir (str): Path to save the resized images.\n",
    "        target_size (tuple): Target size (width, height) for resized images. Default is (256, 256).\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp','.jfif')):\n",
    "            with Image.open(os.path.join(input_dir, filename)) as img:\n",
    "                resized_img = img.resize(target_size)\n",
    "                resized_img.save(os.path.join(output_dir, filename))\n",
    "\n",
    "    print(\"Image resizing completed successfully.\")\n",
    "\n",
    "# Example usage\n",
    "input_directory = r\"D:\\company\\e-waste\\training\\Reusable\"\n",
    "output_directory = \"reusable\"\n",
    "resize_images(input_directory, output_directory)\n",
    "\n",
    "\n",
    "# Define the directory where you want to save the dataset\n",
    "save_dir = output_directory\n",
    "\n",
    "# Get the absolute path of the directory\n",
    "abs_save_dir = os.path.abspath(save_dir)\n",
    "\n",
    "print(\"Path :\", abs_save_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea5c8c5f-7278-4132-b9b9-868ecc2af0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing: 1.txt\n",
      "Removing: 10.txt\n",
      "Removing: 11.txt\n",
      "Removing: 12.txt\n",
      "Removing: 13.txt\n",
      "Removing: 14.txt\n",
      "Removing: 15.txt\n",
      "Removing: 151.txt\n",
      "Removing: 152.txt\n",
      "Removing: 153.txt\n",
      "Removing: 154.txt\n",
      "Removing: 155.txt\n",
      "Removing: 156.txt\n",
      "Removing: 157.txt\n",
      "Removing: 158.txt\n",
      "Removing: 159.txt\n",
      "Removing: 16.txt\n",
      "Removing: 160.txt\n",
      "Removing: 161.txt\n",
      "Removing: 162.txt\n",
      "Removing: 163.txt\n",
      "Removing: 164.txt\n",
      "Removing: 165.txt\n",
      "Removing: 166.txt\n",
      "Removing: 167.txt\n",
      "Removing: 168.txt\n",
      "Removing: 169.txt\n",
      "Removing: 17.txt\n",
      "Removing: 170.txt\n",
      "Removing: 171.txt\n",
      "Removing: 172.txt\n",
      "Removing: 173.txt\n",
      "Removing: 174.txt\n",
      "Removing: 175.txt\n",
      "Removing: 176.txt\n",
      "Removing: 177.txt\n",
      "Removing: 178.txt\n",
      "Removing: 179.txt\n",
      "Removing: 18.txt\n",
      "Removing: 180.txt\n",
      "Removing: 181.txt\n",
      "Removing: 182.txt\n",
      "Removing: 183.txt\n",
      "Removing: 184.txt\n",
      "Removing: 185.txt\n",
      "Removing: 186.txt\n",
      "Removing: 187.txt\n",
      "Removing: 188.txt\n",
      "Removing: 189.txt\n",
      "Removing: 19.txt\n",
      "Removing: 190.txt\n",
      "Removing: 191.txt\n",
      "Removing: 192.txt\n",
      "Removing: 193.txt\n",
      "Removing: 194.txt\n",
      "Removing: 195.txt\n",
      "Removing: 196.txt\n",
      "Removing: 197.txt\n",
      "Removing: 198.txt\n",
      "Removing: 199.txt\n",
      "Removing: 2.txt\n",
      "Removing: 20.txt\n",
      "Removing: 200.txt\n",
      "Removing: 202.txt\n",
      "Removing: 203.txt\n",
      "Removing: 204.txt\n",
      "Removing: 205.txt\n",
      "Removing: 206.txt\n",
      "Removing: 207.txt\n",
      "Removing: 208.txt\n",
      "Removing: 209.txt\n",
      "Removing: 21.txt\n",
      "Removing: 210.txt\n",
      "Removing: 211.txt\n",
      "Removing: 212.txt\n",
      "Removing: 213.txt\n",
      "Removing: 214.txt\n",
      "Removing: 215.txt\n",
      "Removing: 216.txt\n",
      "Removing: 217.txt\n",
      "Removing: 22.txt\n",
      "Removing: 23.txt\n",
      "Removing: 230.txt\n",
      "Removing: 231.txt\n",
      "Removing: 232.txt\n",
      "Removing: 233.txt\n",
      "Removing: 235.txt\n",
      "Removing: 236.txt\n",
      "Removing: 237.txt\n",
      "Removing: 238.txt\n",
      "Removing: 239.txt\n",
      "Removing: 24.txt\n",
      "Removing: 240.txt\n",
      "Removing: 241.txt\n",
      "Removing: 242.txt\n",
      "Removing: 243.txt\n",
      "Removing: 244.txt\n",
      "Removing: 245.txt\n",
      "Removing: 246.txt\n",
      "Removing: 247.txt\n",
      "Removing: 248.txt\n",
      "Removing: 249.txt\n",
      "Removing: 25.txt\n",
      "Removing: 250.txt\n",
      "Removing: 251.txt\n",
      "Removing: 252.txt\n",
      "Removing: 253.txt\n",
      "Removing: 254.txt\n",
      "Removing: 255.txt\n",
      "Removing: 256.txt\n",
      "Removing: 257.txt\n",
      "Removing: 258.txt\n",
      "Removing: 259.txt\n",
      "Removing: 26.txt\n",
      "Removing: 261.txt\n",
      "Removing: 262.txt\n",
      "Removing: 263.txt\n",
      "Removing: 264.txt\n",
      "Removing: 265.txt\n",
      "Removing: 266.txt\n",
      "Removing: 267.txt\n",
      "Removing: 268.txt\n",
      "Removing: 269.txt\n",
      "Removing: 27.txt\n",
      "Removing: 28.txt\n",
      "Removing: 29.txt\n",
      "Removing: 3.txt\n",
      "Removing: 30.txt\n",
      "Removing: 301.txt\n",
      "Removing: 302.txt\n",
      "Removing: 303.txt\n",
      "Removing: 304.txt\n",
      "Removing: 305.txt\n",
      "Removing: 306.txt\n",
      "Removing: 307.txt\n",
      "Removing: 308.txt\n",
      "Removing: 309.txt\n",
      "Removing: 31.txt\n",
      "Removing: 310.txt\n",
      "Removing: 311.txt\n",
      "Removing: 313.txt\n",
      "Removing: 314.txt\n",
      "Removing: 315.txt\n",
      "Removing: 316.txt\n",
      "Removing: 317.txt\n",
      "Removing: 318.txt\n",
      "Removing: 319.txt\n",
      "Removing: 32.txt\n",
      "Removing: 320.txt\n",
      "Removing: 321.txt\n",
      "Removing: 322.txt\n",
      "Removing: 323.txt\n",
      "Removing: 324.txt\n",
      "Removing: 325.txt\n",
      "Removing: 326.txt\n",
      "Removing: 327.txt\n",
      "Removing: 328.txt\n",
      "Removing: 329.txt\n",
      "Removing: 33.txt\n",
      "Removing: 330.txt\n",
      "Removing: 331.txt\n",
      "Removing: 332.txt\n",
      "Removing: 333.txt\n",
      "Removing: 334.txt\n",
      "Removing: 335.txt\n",
      "Removing: 336.txt\n",
      "Removing: 337.txt\n",
      "Removing: 338.txt\n",
      "Removing: 339.txt\n",
      "Removing: 34.txt\n",
      "Removing: 340.txt\n",
      "Removing: 341.txt\n",
      "Removing: 342.txt\n",
      "Removing: 343.txt\n",
      "Removing: 344.txt\n",
      "Removing: 345.txt\n",
      "Removing: 346.txt\n",
      "Removing: 35.txt\n",
      "Removing: 4.txt\n",
      "Removing: 451.txt\n",
      "Removing: 452.txt\n",
      "Removing: 453.txt\n",
      "Removing: 454.txt\n",
      "Removing: 455.txt\n",
      "Removing: 456.txt\n",
      "Removing: 457.txt\n",
      "Removing: 458.txt\n",
      "Removing: 459.txt\n",
      "Removing: 460.txt\n",
      "Removing: 461.txt\n",
      "Removing: 462.txt\n",
      "Removing: 463.txt\n",
      "Removing: 464.txt\n",
      "Removing: 465.txt\n",
      "Removing: 466.txt\n",
      "Removing: 467.txt\n",
      "Removing: 468.txt\n",
      "Removing: 469.txt\n",
      "Removing: 470.txt\n",
      "Removing: 471.txt\n",
      "Removing: 472.txt\n",
      "Removing: 473.txt\n",
      "Removing: 474.txt\n",
      "Removing: 475.txt\n",
      "Removing: 476.txt\n",
      "Removing: 477.txt\n",
      "Removing: 478.txt\n",
      "Removing: 479.txt\n",
      "Removing: 480.txt\n",
      "Removing: 481.txt\n",
      "Removing: 482.txt\n",
      "Removing: 483.txt\n",
      "Removing: 484.txt\n",
      "Removing: 485.txt\n",
      "Removing: 486.txt\n",
      "Removing: 487.txt\n",
      "Removing: 488.txt\n",
      "Removing: 489.txt\n",
      "Removing: 490.txt\n",
      "Removing: 491.txt\n",
      "Removing: 492.txt\n",
      "Removing: 493.txt\n",
      "Removing: 494.txt\n",
      "Removing: 495.txt\n",
      "Removing: 496.txt\n",
      "Removing: 497.txt\n",
      "Removing: 498.txt\n",
      "Removing: 499.txt\n",
      "Removing: 5.txt\n",
      "Removing: 500.txt\n",
      "Removing: 501.txt\n",
      "Removing: 502.txt\n",
      "Removing: 503.txt\n",
      "Removing: 504.txt\n",
      "Removing: 505.txt\n",
      "Removing: 506.txt\n",
      "Removing: 507.txt\n",
      "Removing: 508.txt\n",
      "Removing: 509.txt\n",
      "Removing: 510.txt\n",
      "Removing: 511.txt\n",
      "Removing: 512.txt\n",
      "Removing: 513.txt\n",
      "Removing: 514.txt\n",
      "Removing: 515.txt\n",
      "Removing: 516.txt\n",
      "Removing: 517.txt\n",
      "Removing: 518.txt\n",
      "Removing: 519.txt\n",
      "Removing: 520.txt\n",
      "Removing: 521.txt\n",
      "Removing: 522.txt\n",
      "Removing: 523.txt\n",
      "Removing: 524.txt\n",
      "Removing: 525.txt\n",
      "Removing: 526.txt\n",
      "Removing: 527.txt\n",
      "Removing: 528.txt\n",
      "Removing: 530.txt\n",
      "Removing: 531.txt\n",
      "Removing: 532.txt\n",
      "Removing: 533.txt\n",
      "Removing: 534.txt\n",
      "Removing: 535.txt\n",
      "Removing: 536.txt\n",
      "Removing: 537.txt\n",
      "Removing: 538.txt\n",
      "Removing: 539.txt\n",
      "Removing: 540.txt\n",
      "Removing: 541.txt\n",
      "Removing: 542.txt\n",
      "Removing: 543.txt\n",
      "Removing: 544.txt\n",
      "Removing: 545.txt\n",
      "Removing: 546.txt\n",
      "Removing: 547.txt\n",
      "Removing: 548.txt\n",
      "Removing: 549.txt\n",
      "Removing: 550.txt\n",
      "Removing: 551.txt\n",
      "Removing: 552.txt\n",
      "Removing: 553.txt\n",
      "Removing: 554.txt\n",
      "Removing: 555.txt\n",
      "Removing: 556.txt\n",
      "Removing: 557.txt\n",
      "Removing: 558.txt\n",
      "Removing: 559.txt\n",
      "Removing: 560.txt\n",
      "Removing: 561.txt\n",
      "Removing: 562.txt\n",
      "Removing: 563.txt\n",
      "Removing: 564.txt\n",
      "Removing: 565.txt\n",
      "Removing: 566.txt\n",
      "Removing: 567.txt\n",
      "Removing: 568.txt\n",
      "Removing: 569.txt\n",
      "Removing: 570.txt\n",
      "Removing: 571.txt\n",
      "Removing: 572.txt\n",
      "Removing: 573.txt\n",
      "Removing: 574.txt\n",
      "Removing: 575.txt\n",
      "Removing: 576.txt\n",
      "Removing: 577.txt\n",
      "Removing: 578.txt\n",
      "Removing: 579.txt\n",
      "Removing: 580.txt\n",
      "Removing: 581.txt\n",
      "Removing: 582.txt\n",
      "Removing: 583.txt\n",
      "Removing: 584.txt\n",
      "Removing: 585.txt\n",
      "Removing: 586.txt\n",
      "Removing: 587.txt\n",
      "Removing: 588.txt\n",
      "Removing: 589.txt\n",
      "Removing: 590.txt\n",
      "Removing: 591.txt\n",
      "Removing: 592.txt\n",
      "Removing: 593.txt\n",
      "Removing: 594.txt\n",
      "Removing: 595.txt\n",
      "Removing: 596.txt\n",
      "Removing: 597.txt\n",
      "Removing: 598.txt\n",
      "Removing: 599.txt\n",
      "Removing: 6.txt\n",
      "Removing: 600.txt\n",
      "Removing: 601.txt\n",
      "Removing: 602.txt\n",
      "Removing: 603.txt\n",
      "Removing: 604.txt\n",
      "Removing: 605.txt\n",
      "Removing: 606.txt\n",
      "Removing: 607.txt\n",
      "Removing: 608.txt\n",
      "Removing: 609.txt\n",
      "Removing: 610.txt\n",
      "Removing: 611.txt\n",
      "Removing: 612.txt\n",
      "Removing: 613.txt\n",
      "Removing: 614.txt\n",
      "Removing: 615.txt\n",
      "Removing: 616.txt\n",
      "Removing: 617.txt\n",
      "Removing: 618.txt\n",
      "Removing: 619.txt\n",
      "Removing: 620.txt\n",
      "Removing: 621.txt\n",
      "Removing: 622.txt\n",
      "Removing: 623.txt\n",
      "Removing: 624.txt\n",
      "Removing: 625.txt\n",
      "Removing: 626.txt\n",
      "Removing: 627(1).txt\n",
      "Removing: 627.txt\n",
      "Removing: 628(1).txt\n",
      "Removing: 628.txt\n",
      "Removing: 629(1).txt\n",
      "Removing: 629.txt\n",
      "Removing: 630(1).txt\n",
      "Removing: 630.txt\n",
      "Removing: 631.txt\n",
      "Removing: 632.txt\n",
      "Removing: 633.txt\n",
      "Removing: 634.txt\n",
      "Removing: 635(1).txt\n",
      "Removing: 635.txt\n",
      "Removing: 636.txt\n",
      "Removing: 637.txt\n",
      "Removing: 7.txt\n",
      "Removing: 751.txt\n",
      "Removing: 752.txt\n",
      "Removing: 753.txt\n",
      "Removing: 754.txt\n",
      "Removing: 755.txt\n",
      "Removing: 756.txt\n",
      "Removing: 757.txt\n",
      "Removing: 758.txt\n",
      "Removing: 759.txt\n",
      "Removing: 760.txt\n",
      "Removing: 761.txt\n",
      "Removing: 762.txt\n",
      "Removing: 763.txt\n",
      "Removing: 764.txt\n",
      "Removing: 765.txt\n",
      "Removing: 766.txt\n",
      "Removing: 767.txt\n",
      "Removing: 768.txt\n",
      "Removing: 769.txt\n",
      "Removing: 770.txt\n",
      "Removing: 771.txt\n",
      "Removing: 772.txt\n",
      "Removing: 773.txt\n",
      "Removing: 774.txt\n",
      "Removing: 775.txt\n",
      "Removing: 776.txt\n",
      "Removing: 777.txt\n",
      "Removing: 778.txt\n",
      "Removing: 779.txt\n",
      "Removing: 780.txt\n",
      "Removing: 781.txt\n",
      "Removing: 782.txt\n",
      "Removing: 783.txt\n",
      "Removing: 784.txt\n",
      "Removing: 785.txt\n",
      "Removing: 786.txt\n",
      "Removing: 787.txt\n",
      "Removing: 788.txt\n",
      "Removing: 789.txt\n",
      "Removing: 790.txt\n",
      "Removing: 791.txt\n",
      "Removing: 792.txt\n",
      "Removing: 793.txt\n",
      "Removing: 794.txt\n",
      "Removing: 795.txt\n",
      "Removing: 796.txt\n",
      "Removing: 797.txt\n",
      "Removing: 798.txt\n",
      "Removing: 799.txt\n",
      "Removing: 8.txt\n",
      "Removing: 800.txt\n",
      "Removing: 801.txt\n",
      "Removing: 802.txt\n",
      "Removing: 803.txt\n",
      "Removing: 807.txt\n",
      "Removing: 808.txt\n",
      "Removing: 809.txt\n",
      "Removing: 810.txt\n",
      "Removing: 811.txt\n",
      "Removing: 812.txt\n",
      "Removing: 813.txt\n",
      "Removing: 814.txt\n",
      "Removing: 815.txt\n",
      "Removing: 816.txt\n",
      "Removing: 9.txt\n",
      "Removing: 901.txt\n",
      "Removing: 902.txt\n",
      "Removing: 903.txt\n",
      "Removing: abc.txt\n",
      "Removing: Copy of IMG_20200328_131938.txt\n",
      "Removing: Copy of IMG_20200328_131942.txt\n",
      "Removing: Copy of IMG_20200328_131944.txt\n",
      "Removing: Copy of IMG_20200328_131952.txt\n",
      "Removing: Copy of IMG_20200328_131958.txt\n",
      "Removing: Copy of IMG_20200328_132000.txt\n",
      "Removing: Copy of IMG_20200328_132038.txt\n",
      "Removing: Copy of IMG_20200328_132051.txt\n",
      "Removing: Copy of IMG_20200328_132109.txt\n",
      "Removing: Copy of IMG_20200328_132116.txt\n",
      "Removing: Copy of IMG_20200328_132119.txt\n",
      "Removing: Copy of IMG_20200328_132120.txt\n",
      "Removing: Copy of IMG_20200328_132124.txt\n",
      "Removing: Copy of IMG_20200328_132129.txt\n",
      "Removing: Copy of IMG_20200328_132131.txt\n",
      "Removing: Copy of IMG_20200328_132135.txt\n",
      "Removing: Copy of IMG_20200328_132149.txt\n",
      "Removing: Copy of IMG_20200328_132151.txt\n",
      "Removing: Copy of IMG_20200328_132156.txt\n",
      "Removing: Copy of IMG_20200328_134825.txt\n",
      "Removing: Copy of IMG_20200328_134847.txt\n",
      "Removing: Copy of IMG_20200328_134852.txt\n",
      "Removing: Copy of IMG_20200328_134903.txt\n",
      "Removing: Copy of IMG_20200328_134906.txt\n",
      "Removing: Copy of IMG_20200328_135222.txt\n",
      "Removing: Copy of IMG_20200328_135224.txt\n",
      "Removing: Copy of IMG_20200328_135230.txt\n",
      "Removing: Copy of IMG_20200328_135237.txt\n",
      "Removing: Copy of IMG_20200328_135240.txt\n",
      "Removing: Copy of IMG_20200328_135302.txt\n",
      "Removing: Copy of IMG_20200328_135306.txt\n",
      "Removing: Copy of IMG_20200328_135312.txt\n",
      "Removing: Copy of IMG_20200328_135435.txt\n",
      "Removing: Copy of IMG_20200328_135457.txt\n",
      "Removing: Copy of IMG_20200328_135503.txt\n",
      "Removing: Copy of IMG_20200328_135507.txt\n",
      "Removing: Copy of IMG_20200328_135512.txt\n",
      "Removing: Copy of IMG_20200328_140053.txt\n",
      "Removing: Copy of IMG_20200328_140056.txt\n",
      "Removing: Copy of IMG_20200328_140104.txt\n",
      "Removing: Copy of IMG_20200328_140107.txt\n",
      "Removing: Copy of IMG_20200328_140109.txt\n",
      "Removing: Copy of IMG_20200328_140112.txt\n",
      "Removing: Copy of IMG_20200328_140115.txt\n",
      "Removing: Copy of IMG_20200328_140117.txt\n",
      "Removing: Copy of IMG_20200328_140124.txt\n",
      "Removing: Copy of IMG_20200328_214915.txt\n",
      "Removing: Copy of IMG_20200328_214955.txt\n",
      "Removing: Copy of IMG_20200328_215002.txt\n",
      "Removing: Copy of IMG_20200328_215102.txt\n",
      "Removing: Copy of IMG_20200328_215107.txt\n",
      "Removing: Copy of IMG_20200328_215110.txt\n",
      "Removing: Copy of IMG_20200328_215118.txt\n",
      "Removing: Copy of IMG_20200328_221548.txt\n",
      "Removing: Copy of IMG_20200328_221604.txt\n",
      "Removing: Copy of IMG_20200328_221613.txt\n",
      "Removing: Copy of IMG_20200328_221622.txt\n",
      "Removing: Copy of IMG_20200328_221651.txt\n",
      "Removing: Copy of IMG_20200328_221706.txt\n",
      "Removing: Copy of IMG_20200328_221715.txt\n",
      "Removing: Copy of IMG_20200328_222043.txt\n",
      "Removing: Copy of IMG_20200328_222053.txt\n",
      "Removing: Copy of IMG_20200328_222058.txt\n",
      "Removing: Copy of IMG_20200328_222105.txt\n",
      "Removing: Copy of IMG_20200328_222123.txt\n",
      "Removing: dataset_labels.csv\n",
      "Removing: IMG-20200328-WA0024.txt\n",
      "Removing: IMG-20200328-WA0025.txt\n",
      "Removing: IMG-20200328-WA0026.txt\n",
      "Removing: IMG-20200328-WA0027.txt\n",
      "Removing: IMG-20200328-WA0028.txt\n",
      "Removing: IMG-20200328-WA0029.txt\n",
      "Removing: IMG-20200328-WA0030(1).txt\n",
      "Removing: IMG-20200328-WA0030.txt\n",
      "Removing: IMG-20200328-WA0031.txt\n",
      "Removing: IMG-20200328-WA0032.txt\n",
      "Removing: IMG-20200328-WA0033.txt\n",
      "Removing: IMG-20200328-WA0034.txt\n",
      "Removing: IMG-20200328-WA0037.txt\n",
      "Removing: IMG-20200328-WA0039.txt\n",
      "Removing: IMG-20200328-WA0040.txt\n",
      "Removing: IMG-20200328-WA0041.txt\n",
      "Removing: IMG-20200328-WA0042.txt\n",
      "Removing: IMG-20200328-WA0043.txt\n",
      "Removing: IMG-20200328-WA0044.txt\n",
      "Removing: IMG-20200328-WA0045.txt\n",
      "Removing: IMG-20200328-WA0046.txt\n",
      "Removing: IMG-20200328-WA0047.txt\n",
      "Removing: IMG-20200328-WA0048(1).txt\n",
      "Removing: IMG-20200328-WA0049.txt\n",
      "Removing: IMG-20200329-WA0066.txt\n",
      "Removing: IMG-20200329-WA0067.txt\n",
      "Removing: IMG-20200329-WA0068.txt\n",
      "Removing: IMG-20200329-WA0069.txt\n",
      "Removing: IMG-20200329-WA0070.txt\n",
      "Removing: IMG-20200329-WA0071.txt\n",
      "Removing: IMG-20200329-WA0072.txt\n",
      "Removing: IMG-20200329-WA0073.txt\n",
      "Removing: IMG-20200329-WA0074.txt\n",
      "Removing: IMG-20200329-WA0075.txt\n",
      "Removing: IMG-20200329-WA0076.txt\n",
      "Removing: IMG-20200329-WA0077.txt\n",
      "Removing: IMG-20200329-WA0078.txt\n",
      "Removing: IMG_20190211_195144.txt\n",
      "Removing: IMG_20190211_195203.txt\n",
      "Removing: IMG_20190211_195304.txt\n",
      "Removing: IMG_20190211_195311.txt\n",
      "Removing: IMG_20190211_195323.txt\n",
      "Removing: IMG_20190211_195330.txt\n",
      "Removing: IMG_20190211_195336.txt\n",
      "Removing: IMG_20190211_195411.txt\n",
      "Removing: IMG_20190211_195417.txt\n",
      "Removing: IMG_20190211_195428.txt\n",
      "Removing: IMG_20190211_195437.txt\n",
      "Removing: IMG_20190211_195440.txt\n",
      "Removing: IMG_20190211_195445.txt\n",
      "Removing: IMG_20190211_195510.txt\n",
      "Removing: IMG_20190211_195517.txt\n",
      "Removing: IMG_20190211_195528.txt\n",
      "Removing: IMG_20190211_195541.txt\n",
      "Removing: IMG_20190211_195619.txt\n",
      "Removing: IMG_20190211_195623.txt\n",
      "Removing: IMG_20190211_195640.txt\n",
      "Removing: IMG_20190211_195643.txt\n",
      "Removing: IMG_20190211_195653.txt\n",
      "Removing: IMG_20190211_195710.txt\n",
      "Removing: IMG_20190211_195740.txt\n",
      "Removing: IMG_20190211_195756.txt\n",
      "Removing: IMG_20190211_195804.txt\n",
      "Removing: IMG_20190211_195813.txt\n",
      "Removing: IMG_20190211_195818.txt\n",
      "Removing: IMG_20190211_195824.txt\n",
      "Removing: IMG_20190211_195829.txt\n",
      "Removing: IMG_20190211_195835.txt\n",
      "Removing: IMG_20190211_195842.txt\n",
      "Removing: IMG_20190211_211014.txt\n",
      "Removing: IMG_20190211_211021.txt\n",
      "Removing: IMG_20190211_211027.txt\n",
      "Removing: IMG_20190211_211033.txt\n",
      "Removing: IMG_20190211_211051.txt\n",
      "Removing: IMG_20190211_211103.txt\n",
      "Removing: IMG_20190211_211106.txt\n",
      "Removing: IMG_20190211_211118.txt\n",
      "Removing: IMG_20190211_211542.txt\n",
      "Removing: IMG_20190211_211549.txt\n",
      "Removing: IMG_20190211_211551.txt\n",
      "Removing: IMG_20190211_211553.txt\n",
      "Removing: IMG_20190211_211559.txt\n",
      "Removing: IMG_20190211_211605.txt\n",
      "Removing: IMG_20190211_211608.txt\n",
      "Removing: IMG_20190211_211612.txt\n",
      "Removing: IMG_20190211_211617.txt\n",
      "Removing: IMG_20190211_211620.txt\n",
      "Removing: IMG_20190211_211623.txt\n",
      "Removing: IMG_20190211_211635.txt\n",
      "Removing: IMG_20190211_211642.txt\n",
      "Removing: IMG_20190211_211654.txt\n",
      "Removing: IMG_20190211_211704.txt\n",
      "Removing: IMG_20190211_211706.txt\n",
      "Removing: IMG_20190211_211709.txt\n",
      "Removing: IMG_20190211_211711.txt\n",
      "Removing: IMG_20190211_211715.txt\n",
      "Removing: IMG_20190211_211717.txt\n",
      "Removing: IMG_20190211_211719.txt\n",
      "Removing: IMG_20190211_211724.txt\n",
      "Removing: IMG_20190211_211739.txt\n",
      "Removing: IMG_20190211_211743.txt\n",
      "Removing: IMG_20190211_211754.txt\n",
      "Removing: IMG_20190211_211757.txt\n",
      "Removing: IMG_20190211_211759.txt\n",
      "Removing: IMG_20190211_211802.txt\n",
      "Removing: IMG_20190211_211804.txt\n",
      "Removing: IMG_20190211_211807.txt\n",
      "Removing: IMG_20190211_211810.txt\n",
      "Removing: IMG_20190211_211819.txt\n",
      "Removing: IMG_20190211_211824.txt\n",
      "Removing: IMG_20190211_211835.txt\n",
      "Removing: IMG_20190211_211848.txt\n",
      "Removing: IMG_20190211_211850.txt\n",
      "Removing: IMG_20190211_211856.txt\n",
      "Removing: IMG_20190211_211907.txt\n",
      "Removing: IMG_20190211_211908.txt\n",
      "Removing: IMG_20190211_211909.txt\n",
      "Removing: IMG_20190211_211911.txt\n",
      "Removing: IMG_20190211_211913.txt\n",
      "Removing: IMG_20190211_211913_01.txt\n",
      "Removing: IMG_20190211_211920.txt\n",
      "Removing: IMG_20190211_211922.txt\n",
      "Removing: IMG_20190211_211924.txt\n",
      "Removing: IMG_20190211_211930.txt\n",
      "Removing: IMG_20190211_211933.txt\n",
      "Removing: IMG_20190211_211935.txt\n",
      "Removing: IMG_20190211_211941.txt\n",
      "Removing: IMG_20190211_212004.txt\n",
      "Removing: IMG_20190211_212009.txt\n",
      "Removing: IMG_20190211_212013.txt\n",
      "Removing: IMG_20190211_212015.txt\n",
      "Removing: IMG_20190211_212018.txt\n",
      "Removing: IMG_20190211_212114.txt\n",
      "Removing: IMG_20190211_212118.txt\n",
      "Removing: IMG_20190211_212124.txt\n",
      "Removing: IMG_20190211_212127.txt\n",
      "Removing: IMG_20190211_212130.txt\n",
      "Removing: IMG_20190212_213839.txt\n",
      "Removing: IMG_20190212_213851.txt\n",
      "Removing: IMG_20190212_213854.txt\n",
      "Removing: IMG_20190212_213913.txt\n",
      "Removing: IMG_20190212_213917.txt\n",
      "Removing: IMG_20190212_213920.txt\n",
      "Removing: IMG_20190212_213925.txt\n",
      "Removing: IMG_20190212_213929.txt\n",
      "Removing: IMG_20190212_213931.txt\n",
      "Removing: IMG_20190212_213935.txt\n",
      "Removing: IMG_20190212_214037.txt\n",
      "Removing: IMG_20190212_214043.txt\n",
      "Removing: IMG_20190212_214046.txt\n",
      "Removing: IMG_20190212_214051.txt\n",
      "Removing: IMG_20190212_214057.txt\n",
      "Removing: IMG_20190212_214104.txt\n",
      "Removing: IMG_20190212_214109.txt\n",
      "Removing: IMG_20190212_214113.txt\n",
      "Removing: IMG_20190212_214117.txt\n",
      "Removing: IMG_20190212_214120.txt\n",
      "Removing: IMG_20190212_214133.txt\n",
      "Removing: IMG_20190212_214136.txt\n",
      "Removing: IMG_20190212_214137.txt\n",
      "Removing: IMG_20190212_214141.txt\n",
      "Removing: IMG_20190212_214146.txt\n",
      "Removing: IMG_20190212_214151.txt\n",
      "Removing: IMG_20190212_214154.txt\n",
      "Removing: IMG_20190212_214158.txt\n",
      "Removing: IMG_20190212_214207.txt\n",
      "Removing: IMG_20190212_214211.txt\n",
      "Removing: IMG_20190212_214214.txt\n",
      "Removing: IMG_20190212_214218.txt\n",
      "Removing: IMG_20190212_214227.txt\n",
      "Removing: IMG_20190212_214231.txt\n",
      "Removing: IMG_20190212_214234.txt\n",
      "Removing: IMG_20190212_214240.txt\n",
      "Removing: IMG_20190212_214242.txt\n",
      "Removing: IMG_20190212_214259.txt\n",
      "Removing: IMG_20190212_214301.txt\n",
      "Removing: IMG_20190212_214303.txt\n",
      "Removing: IMG_20190212_214309.txt\n",
      "Removing: IMG_20190212_214311.txt\n",
      "Removing: IMG_20190212_214313.txt\n",
      "Removing: IMG_20190212_214315.txt\n",
      "Removing: IMG_20190212_214404.txt\n",
      "Removing: IMG_20190212_214405.txt\n",
      "Removing: IMG_20190212_214441.txt\n",
      "Removing: IMG_20190212_214446.txt\n",
      "Removing: IMG_20190212_214451.txt\n",
      "Removing: IMG_20190212_214452.txt\n",
      "Removing: IMG_20190212_214503.txt\n",
      "Removing: IMG_20190212_214507.txt\n",
      "Removing: IMG_20190212_214509.txt\n",
      "Removing: IMG_20190212_214514.txt\n",
      "Removing: IMG_20190212_214519.txt\n",
      "Removing: IMG_20190212_214523.txt\n",
      "Removing: IMG_20190212_214524.txt\n",
      "Removing: IMG_20190212_214529.txt\n",
      "Removing: IMG_20190212_214532.txt\n",
      "Removing: IMG_20190212_214541.txt\n",
      "Removing: IMG_20190212_214550.txt\n",
      "Removing: IMG_20190212_214558.txt\n",
      "Removing: IMG_20190212_214607.txt\n",
      "Removing: IMG_20190212_214612.txt\n",
      "Removing: IMG_20190212_214615.txt\n",
      "Removing: IMG_20190212_214617.txt\n",
      "Removing: IMG_20190212_214620.txt\n",
      "Removing: IMG_20190212_214628.txt\n",
      "Removing: IMG_20190212_214635.txt\n",
      "Removing: IMG_20190212_214641.txt\n",
      "Removing: IMG_20190212_214643.txt\n",
      "Removing: IMG_20190212_214652.txt\n",
      "Removing: IMG_20190212_214654.txt\n",
      "Removing: IMG_20190212_214702.txt\n",
      "Removing: IMG_20190212_214706.txt\n",
      "Removing: IMG_20190212_214710.txt\n",
      "Removing: IMG_20190212_214714.txt\n",
      "Removing: IMG_20190212_214717.txt\n",
      "Removing: IMG_20190212_214721.txt\n",
      "Removing: IMG_20190212_214728.txt\n",
      "Removing: IMG_20190212_214732.txt\n",
      "Removing: IMG_20200328_131159.txt\n",
      "Removing: IMG_20200328_131230.txt\n",
      "Removing: IMG_20200328_131236.txt\n",
      "Removing: IMG_20200328_131300.txt\n",
      "Removing: IMG_20200328_131316.txt\n",
      "Removing: IMG_20200328_131322.txt\n",
      "Removing: IMG_20200328_131329.txt\n",
      "Removing: IMG_20200328_131506.txt\n",
      "Removing: IMG_20200328_131510.txt\n",
      "Removing: IMG_20200328_131519.txt\n",
      "Removing: IMG_20200328_131600.txt\n",
      "Removing: IMG_20200328_131615.txt\n",
      "Removing: IMG_20200328_131708.txt\n",
      "Removing: IMG_20200328_131720.txt\n",
      "Removing: IMG_20200328_215102.txt\n",
      "Removing: IMG_20200328_215107.txt\n",
      "Removing: IMG_20200328_215110.txt\n",
      "Removing: IMG_20200329_142515.txt\n",
      "Removing: IMG_20200329_142521.txt\n",
      "Removing: IMG_20200329_142525.txt\n",
      "Removing: IMG_20200329_142530.txt\n",
      "Removing: IMG_20200329_142535.txt\n",
      "Removing: IMG_20200329_142542.txt\n",
      "Removing: IMG_20200329_142558.txt\n",
      "Removing: IMG_20200329_142612.txt\n",
      "Removing: IMG_20200329_142615.txt\n",
      "Removing: IMG_20200329_142619(1).txt\n",
      "Removing: IMG_20200329_142619.txt\n",
      "Removing: IMG_20200329_142626.txt\n",
      "Removing: IMG_20200329_142649.txt\n",
      "Removing: IMG_20200329_142653.txt\n",
      "Removing: IMG_20200329_142656.txt\n",
      "Removing: IMG_20200329_142704.txt\n",
      "Removing: IMG_20200329_142707.txt\n",
      "Removing: IMG_20200329_142718.txt\n",
      "Removing: IMG_20200329_142727.txt\n",
      "Removing: IMG_20200329_142734.txt\n",
      "Removing: IMG_20200329_142737.txt\n",
      "Removing: IMG_20200329_142740.txt\n",
      "Removing: IMG_20200329_142745.txt\n",
      "Removing: IMG_20200329_142751.txt\n",
      "Removing: IMG_20200329_142759.txt\n",
      "Removing: IMG_20200329_152619.txt\n",
      "Removing: IMG_20200329_152622.txt\n",
      "Removing: IMG_20200329_152625.txt\n",
      "Removing: IMG_20200329_152635.txt\n",
      "Removing: IMG_20200329_152638.txt\n",
      "Removing: IMG_20200329_152642.txt\n",
      "Removing: IMG_20200329_152649.txt\n",
      "Removing: IMG_20200329_152654.txt\n",
      "Removing: IMG_20200329_152659.txt\n",
      "Removing: IMG_20200329_152704.txt\n",
      "Removing: IMG_20200329_152708.txt\n",
      "Removing: IMG_20200329_152720.txt\n",
      "Removing: IMG_20200329_152730.txt\n",
      "Removing: IMG_20200329_152734.txt\n",
      "Removing: IMG_20200329_152735.txt\n",
      "Removing: IMG_20200329_152741.txt\n",
      "Removing: IMG_20200329_152746.txt\n",
      "Removing: IMG_20200329_152752.txt\n",
      "Removing: IMG_20200329_152755.txt\n",
      "Removing: IMG_20200329_152800.txt\n",
      "Removing: IMG_20200329_152804.txt\n",
      "Removing: IMG_20200329_152836.txt\n",
      "Removing: IMG_20200329_152840(1).txt\n",
      "Removing: IMG_20200329_152844.txt\n",
      "Removing: IMG_20200329_152857.txt\n",
      "Removing: IMG_20200329_152858.txt\n",
      "Removing: IMG_20200329_201009.txt\n",
      "Removing: IMG_20200329_201011.txt\n",
      "Removing: IMG_20200329_201015.txt\n",
      "Removing: IMG_20200329_201018.txt\n",
      "Removing: IMG_20200329_201042.txt\n",
      "Removing: IMG_20200329_201047.txt\n",
      "Removing: IMG_20200329_201049.txt\n",
      "Removing: IMG_20200329_201051.txt\n",
      "Removing: IMG_20200329_201109.txt\n",
      "Removing: IMG_20200329_201113.txt\n",
      "Removing: IMG_20200329_201125.txt\n",
      "Removing: IMG_20200329_201129.txt\n",
      "Removing: IMG_20200329_201131.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def remove_non_image_files(folder_path):\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"The folder '{folder_path}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    # Get a list of all files in the directory\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    # Iterate through each file\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        # Check if it's a file\n",
    "        if os.path.isfile(file_path):\n",
    "            # Check if it's an image file (you can extend this condition if needed)\n",
    "            if not file.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp')):\n",
    "                print(f\"Removing: {file}\")\n",
    "                os.remove(file_path)\n",
    "\n",
    "# Example usage\n",
    "dataset_folder = r\"D:\\company\\archive\\data\"\n",
    "remove_non_image_files(dataset_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "618c401c-490e-475e-9cb1-1546c90f5cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image cropping completed successfully.\n"
     ]
    }
   ],
   "source": [
    "def crop_images(input_dir, output_dir, crop_box):\n",
    "    \"\"\"\n",
    "    Crop images in the input directory and save them to the output directory.\n",
    "\n",
    "    Parameters:\n",
    "        input_dir (str): Path to the directory containing input images.\n",
    "        output_dir (str): Path to save the cropped images.\n",
    "        crop_box (tuple): Crop box coordinates (left, upper, right, lower).\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp','.jfif')):\n",
    "            with Image.open(os.path.join(input_dir, filename)) as img:\n",
    "                cropped_img = img.crop(crop_box)\n",
    "                cropped_img.save(os.path.join(output_dir, filename))\n",
    "\n",
    "    print(\"Image cropping completed successfully.\")\n",
    "\n",
    "# Example usage\n",
    "input_directory = r\"D:\\company\\NeemSeed\\dataset\\resized_validation\"\n",
    "output_directory = \"cropped_images\"\n",
    "crop_box = (100, 100, 400, 400)  # Example crop box coordinates (left, upper, right, lower)\n",
    "crop_images(input_directory, output_directory, crop_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1f73265-d612-4664-ac65-847e87b6ab73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image rotation completed successfully.\n"
     ]
    }
   ],
   "source": [
    "def rotate_images(input_dir, output_dir, angle):\n",
    "    \"\"\"\n",
    "    Rotate images in the input directory by the specified angle and save them to the output directory.\n",
    "\n",
    "    Parameters:\n",
    "        input_dir (str): Path to the directory containing input images.\n",
    "        output_dir (str): Path to save the rotated images.\n",
    "        angle (float): Angle of rotation in degrees (positive values for clockwise rotation).\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp','.jfif')):\n",
    "            with Image.open(os.path.join(input_dir, filename)) as img:\n",
    "                rotated_img = img.rotate(angle)\n",
    "                rotated_img.save(os.path.join(output_dir, filename))\n",
    "\n",
    "    print(\"Image rotation completed successfully.\")\n",
    "\n",
    "# Example usage\n",
    "input_directory = r\"D:\\company\\NeemSeed\\dataset\\resized_validation\"\n",
    "output_directory = \"rotated_images\"\n",
    "rotation_angle = 90  # Example rotation angle in degrees\n",
    "rotate_images(input_directory, output_directory, rotation_angle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4616979a-8350-4ca0-88b1-b58873750130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image rotation completed successfully.\n"
     ]
    }
   ],
   "source": [
    "def rotate_images(input_dir, output_dir, angle):\n",
    "    \"\"\"\n",
    "    Rotate images in the input directory by the specified angle and save them to the output directory.\n",
    "\n",
    "    Parameters:\n",
    "        input_dir (str): Path to the directory containing input images.\n",
    "        output_dir (str): Path to save the rotated images.\n",
    "        angle (float): Angle of rotation in degrees (positive values for clockwise rotation).\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp','.jfif')):\n",
    "            with Image.open(os.path.join(input_dir, filename)) as img:\n",
    "                rotated_img = img.rotate(angle)\n",
    "                rotated_img.save(os.path.join(output_dir, filename))\n",
    "\n",
    "    print(\"Image rotation completed successfully.\")\n",
    "\n",
    "# Example usage\n",
    "input_directory = r\"D:\\company\\NeemSeed\\dataset\\resized_validation\"\n",
    "output_directory = \"rotated_images\"\n",
    "rotation_angle = 90  # Example rotation angle in degrees\n",
    "rotate_images(input_directory, output_directory, rotation_angle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3fdcbbc-8e9b-4a3c-9520-4db9a2edf002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image flipping completed successfully.\n"
     ]
    }
   ],
   "source": [
    "def flip_images(input_dir, output_dir, mode):\n",
    "    \"\"\"\n",
    "    Flip images in the input directory and save them to the output directory.\n",
    "\n",
    "    Parameters:\n",
    "        input_dir (str): Path to the directory containing input images.\n",
    "        output_dir (str): Path to save the flipped images.\n",
    "        mode (str): Flip mode ('horizontal', 'vertical', or 'both').\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp','.jfif')):\n",
    "            with Image.open(os.path.join(input_dir, filename)) as img:\n",
    "                if mode == 'horizontal':\n",
    "                    flipped_img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                elif mode == 'vertical':\n",
    "                    flipped_img = img.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "                elif mode == 'both':\n",
    "                    flipped_img = img.transpose(Image.ROTATE_180)\n",
    "                flipped_img.save(os.path.join(output_dir, filename))\n",
    "\n",
    "    print(\"Image flipping completed successfully.\")\n",
    "\n",
    "# Example usage\n",
    "input_directory = r\"D:\\company\\NeemSeed\\dataset\\resized_validation\"\n",
    "output_directory = \"flipped_images\"\n",
    "flip_mode = 'horizontal'  # Example flip mode ('horizontal', 'vertical', or 'both')\n",
    "flip_images(input_directory, output_directory, flip_mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "867d1c88-4f6f-4207-b935-52c21bb97df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion to grayscale completed successfully.\n"
     ]
    }
   ],
   "source": [
    "def convert_to_grayscale(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Convert images in the input directory to grayscale and save them to the output directory.\n",
    "\n",
    "    Parameters:\n",
    "        input_dir (str): Path to the directory containing input images.\n",
    "        output_dir (str): Path to save the grayscale images.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp','.jfif')):\n",
    "            with Image.open(os.path.join(input_dir, filename)) as img:\n",
    "                grayscale_img = img.convert('L')\n",
    "                grayscale_img.save(os.path.join(output_dir, filename))\n",
    "\n",
    "    print(\"Conversion to grayscale completed successfully.\")\n",
    "\n",
    "# Example usage\n",
    "input_directory = r\"D:\\company\\NeemSeed\\dataset\\resized_validation\"\n",
    "output_directory = \"grayscale_images\"\n",
    "convert_to_grayscale(input_directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1a79719-06b5-40c0-a196-ac45b6ed18e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image normalization completed successfully.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np  # Add this import statement\n",
    "\n",
    "def normalize_images(input_dir, output_dir, min_val=0, max_val=255):\n",
    "    \"\"\"\n",
    "    Normalize pixel values of images in the input directory and save them to the output directory.\n",
    "\n",
    "    Parameters:\n",
    "        input_dir (str): Path to the directory containing input images.\n",
    "        output_dir (str): Path to save the normalized images.\n",
    "        min_val (int): Minimum pixel value after normalization. Default is 0.\n",
    "        max_val (int): Maximum pixel value after normalization. Default is 255.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp','.jfif')):\n",
    "            with Image.open(os.path.join(input_dir, filename)) as img:\n",
    "                img_array = np.array(img)\n",
    "                normalized_img_array = (img_array - np.min(img_array)) * (max_val - min_val) / (np.max(img_array) - np.min(img_array)) + min_val\n",
    "                normalized_img = Image.fromarray(normalized_img_array.astype(np.uint8))\n",
    "                normalized_img.save(os.path.join(output_dir, filename))\n",
    "\n",
    "    print(\"Image normalization completed successfully.\")\n",
    "\n",
    "# Example usage\n",
    "input_directory = r\"D:\\company\\NeemSeed\\dataset\\resized_validation\"\n",
    "output_directory = \"normalized_images\"\n",
    "normalize_images(input_directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "876f5ed2-291b-4379-ab2a-318f9471315e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image denoising completed successfully.\n"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def denoise_images(input_dir, output_dir, sigma=1):\n",
    "    \"\"\"\n",
    "    Denoise images in the input directory using Gaussian blur and save them to the output directory.\n",
    "\n",
    "    Parameters:\n",
    "        input_dir (str): Path to the directory containing input images.\n",
    "        output_dir (str): Path to save the denoised images.\n",
    "        sigma (float): Standard deviation for Gaussian kernel. Default is 1.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp','.jfif')):\n",
    "            with Image.open(os.path.join(input_dir, filename)) as img:\n",
    "                img_array = np.array(img)\n",
    "                denoised_img_array = gaussian_filter(img_array, sigma=sigma)\n",
    "                denoised_img = Image.fromarray(denoised_img_array.astype(np.uint8))\n",
    "                denoised_img.save(os.path.join(output_dir, filename))\n",
    "\n",
    "    print(\"Image denoising completed successfully.\")\n",
    "\n",
    "# Example usage\n",
    "input_directory = r\"D:\\company\\NeemSeed\\dataset\\resized_validation\"\n",
    "output_directory = \"denoised_images\"\n",
    "denoise_images(input_directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a765c90-6e1e-4b05-a3a4-639660659404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrast enhancement completed successfully.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageOps  # Import ImageOps module\n",
    "\n",
    "def enhance_contrast(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Enhance contrast of images in the input directory using histogram equalization and save them to the output directory.\n",
    "\n",
    "    Parameters:\n",
    "        input_dir (str): Path to the directory containing input images.\n",
    "        output_dir (str): Path to save the contrast-enhanced images.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp','.jfif')):\n",
    "            with Image.open(os.path.join(input_dir, filename)) as img:\n",
    "                enhanced_img = ImageOps.equalize(img)\n",
    "                enhanced_img.save(os.path.join(output_dir, filename))\n",
    "\n",
    "    print(\"Contrast enhancement completed successfully.\")\n",
    "\n",
    "# Example usage\n",
    "input_directory = r\"D:\\company\\NeemSeed\\dataset\\resized_validation\"\n",
    "output_directory = \"enhanced_contrast_images\"\n",
    "enhance_contrast(input_directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3a211e4-4310-4705-88ee-bbf6bbcc3362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian blur application completed successfully.\n"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def apply_gaussian_blur(input_dir, output_dir, sigma=1):\n",
    "    \"\"\"\n",
    "    Apply Gaussian blur filter to images in the input directory and save them to the output directory.\n",
    "\n",
    "    Parameters:\n",
    "        input_dir (str): Path to the directory containing input images.\n",
    "        output_dir (str): Path to save the blurred images.\n",
    "        sigma (float): Standard deviation for Gaussian kernel. Default is 1.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp','.jfif')):\n",
    "            with Image.open(os.path.join(input_dir, filename)) as img:\n",
    "                img_array = np.array(img)\n",
    "                blurred_img_array = gaussian_filter(img_array, sigma=sigma)\n",
    "                blurred_img = Image.fromarray(blurred_img_array.astype(np.uint8))\n",
    "                blurred_img.save(os.path.join(output_dir, filename))\n",
    "\n",
    "    print(\"Gaussian blur application completed successfully.\")\n",
    "\n",
    "# Example usage\n",
    "input_directory = r\"D:\\company\\NeemSeed\\dataset\\resized_validation\"\n",
    "output_directory = \"blurred_images\"\n",
    "gaussian_sigma = 1  # Sigma value for Gaussian blur filter\n",
    "apply_gaussian_blur(input_directory, output_directory, sigma=gaussian_sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c648a98-658b-4379-8c1a-b90bc8e7fbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image merging completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def merge_folders(input_folders, output_folder):\n",
    "    \"\"\"\n",
    "    Merge images from multiple input folders into a single output folder.\n",
    "\n",
    "    Parameters:\n",
    "        input_folders (list): List of input folders to merge.\n",
    "        output_folder (str): Path to the output folder.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    count = 0  # Starting index for renaming images\n",
    "\n",
    "    for folder in input_folders:\n",
    "        for filename in os.listdir(folder):\n",
    "            if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp','.jfif')):\n",
    "                # Generate new filename with index\n",
    "                new_filename = f\"{count}.{filename.split('.')[-1]}\"\n",
    "                # Copy image from input folder to output folder with new name\n",
    "                shutil.copyfile(os.path.join(folder, filename), os.path.join(output_folder, new_filename))\n",
    "                count += 1\n",
    "\n",
    "    print(\"Image merging completed successfully.\")\n",
    "\n",
    "# Example usage\n",
    "input_folders = [\"resized_images\", \"cropped_images\", \"rotated_images\", \"flipped_images\", \n",
    "                 \"grayscale_images\", \"normalized_images\", \"denoised_images\", \"enhanced_contrast_images\", \"filtered_images\"]\n",
    "output_folder = \"dataset_validation\"\n",
    "merge_folders(input_folders, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b398ec6-6b56-45b1-8dd1-3b6cdfb1c548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path of 'preprocessed_dataset': C:\\Users\\cmjot\\dataset_validation\n"
     ]
    }
   ],
   "source": [
    "# Define the directory where you want to save the dataset\n",
    "save_dir = output_folder\n",
    "\n",
    "# Get the absolute path of the directory\n",
    "abs_save_dir = os.path.abspath(save_dir)\n",
    "\n",
    "print(\"Path of 'preprocessed_dataset':\", abs_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "528812ea-9428-4877-b50f-2782a06ab09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion to grayscale completed successfully.\n",
      "Path of 'final_dataset': C:\\Users\\cmjot\\final_dataset_validation\n"
     ]
    }
   ],
   "source": [
    "# Define the input directory\n",
    "input_directory = r\"C:\\Users\\cmjot\\dataset_validation\"\n",
    "\n",
    "# Define the output directory\n",
    "output_directory = \"final_dataset_validation\"\n",
    "\n",
    "# Call the convert_to_grayscale function\n",
    "convert_to_grayscale(input_directory, output_directory)\n",
    "\n",
    "# Define the directory where you want to save the dataset\n",
    "save_dir = output_directory\n",
    "\n",
    "# Get the absolute path of the directory\n",
    "abs_save_dir = os.path.abspath(save_dir)\n",
    "\n",
    "print(\"Path of 'final_dataset':\", abs_save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff68a17-9838-448b-a4d8-cec9ed5b1623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
