{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e65ffd8-28bc-4932-95c2-60e93ba41820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms as T\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import timm\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5ec4c5c-9658-4792-82a5-d446a517b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMG_FOLDER_PATH = r\"D:\\emotion detection\\archive\\dataset\\train0\"\n",
    "VALID_IMG_FOLDER_PATH = r\"D:\\emotion detection\\archive\\dataset\\validation0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b57b7a68-252c-4e1d-81ae-5384505398e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "MODEL_NAME = 'efficientnet_b0'\n",
    "NUM_CLASSES = 7  # Number of classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bd2771a-6a49-46ca-9311-92d0b295a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "train_augs = T.Compose([\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomRotation(degrees=(-20, +20)),\n",
    "    T.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7523c4e-d470-4737-8c3f-176ad5c614ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_augs = T.Compose([\n",
    "    T.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d3b3753-fef9-47b9-b631-0af91a650481",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ImageFolder(TRAIN_IMG_FOLDER_PATH, transform=train_augs)\n",
    "validset = ImageFolder(VALID_IMG_FOLDER_PATH, transform=valid_augs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "064e2d58-5965-4fcf-bc22-e5bbc61302c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of examples in trainset: 315\n",
      "Total no. of examples in validset: 315\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total no. of examples in trainset: {len(trainset)}\")\n",
    "print(f\"Total no. of examples in validset: {len(validset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9071e617-7315-4f14-9a62-e89bdb7d2869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "class_names = trainset.classes\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeca1133-56c2-4dc5-993a-597a0243dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split trainset into train and validation\n",
    "train_indices, val_indices = train_test_split(list(range(len(trainset))), test_size=0.2, random_state=42)\n",
    "train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_indices)\n",
    "val_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "736167fa-31fb-46e6-bbcc-6afb4dffb951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of batches in trainloader: 8\n",
      "Total no. of batches in validloader: 2\n"
     ]
    }
   ],
   "source": [
    "# Create DataLoaders\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "validloader = DataLoader(validset, batch_size=BATCH_SIZE, sampler=val_sampler)\n",
    "\n",
    "print(f\"Total no. of batches in trainloader: {len(trainloader)}\")\n",
    "print(f\"Total no. of batches in validloader: {len(validloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3fca06b-430e-42c7-bdcc-739e5dbb697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "class DepressionModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(DepressionModel, self).__init__()\n",
    "        self.eff_net = timm.create_model(MODEL_NAME, pretrained=True, num_classes=num_classes)\n",
    "\n",
    "    def forward(self, images, labels=None):\n",
    "        logits = self.eff_net(images)\n",
    "        if labels is not None:\n",
    "            loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "            return logits, loss\n",
    "        return logits\n",
    "\n",
    "model = DepressionModel(num_classes=NUM_CLASSES).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47f83a92-6dac-4b33-ae69-31af8642b7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and evaluation functions\n",
    "def train_fn(model, dataloader, optimizer, current_epo):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    tk = tqdm(dataloader, desc=f\"EPOCH [TRAIN] {current_epo + 1}/{EPOCHS}\")\n",
    "\n",
    "    for t, data in enumerate(tk):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits, loss = model(images, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = logits.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        tk.set_postfix({'loss': f'{total_loss / (t + 1):.6f}', 'accuracy': f'{correct / total:.6f}'})\n",
    "\n",
    "    return total_loss / len(dataloader), correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d9dfb3a-86dc-4db7-8994-fe5c428b58be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(model, dataloader, current_epo):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    tk = tqdm(dataloader, desc=f\"EPOCH [VALID] {current_epo + 1}/{EPOCHS}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for t, data in enumerate(tk):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            logits, loss = model(images, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = logits.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            tk.set_postfix({'loss': f'{total_loss / (t + 1):.6f}', 'accuracy': f'{correct / total:.6f}'})\n",
    "\n",
    "    return total_loss / len(dataloader), correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e2d76f9-1e91-45f5-ba0a-d5c8df202347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LR)\n",
    "\n",
    "best_valid_loss = np.Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7bd8676-3214-44e2-b372-891dae343619",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH [TRAIN] 1/15: 100%|██████████| 8/8 [00:02<00:00,  3.65it/s, loss=7.598580, accuracy=0.107143]\n",
      "EPOCH [VALID] 1/15: 100%|██████████| 2/2 [00:00<00:00, 14.23it/s, loss=5.675611, accuracy=0.238095]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH [TRAIN] 2/15: 100%|██████████| 8/8 [00:02<00:00,  3.52it/s, loss=5.485615, accuracy=0.273810]\n",
      "EPOCH [VALID] 2/15: 100%|██████████| 2/2 [00:00<00:00, 17.26it/s, loss=6.819911, accuracy=0.158730]\n",
      "EPOCH [TRAIN] 3/15: 100%|██████████| 8/8 [00:02<00:00,  3.45it/s, loss=4.430485, accuracy=0.293651]\n",
      "EPOCH [VALID] 3/15: 100%|██████████| 2/2 [00:00<00:00, 17.01it/s, loss=7.244960, accuracy=0.126984]\n",
      "EPOCH [TRAIN] 4/15: 100%|██████████| 8/8 [00:02<00:00,  3.44it/s, loss=3.435073, accuracy=0.345238]\n",
      "EPOCH [VALID] 4/15: 100%|██████████| 2/2 [00:00<00:00, 17.37it/s, loss=6.596209, accuracy=0.158730]\n",
      "EPOCH [TRAIN] 5/15: 100%|██████████| 8/8 [00:02<00:00,  3.81it/s, loss=3.194791, accuracy=0.452381]\n",
      "EPOCH [VALID] 5/15: 100%|██████████| 2/2 [00:00<00:00, 18.45it/s, loss=6.083029, accuracy=0.158730]\n",
      "EPOCH [TRAIN] 6/15: 100%|██████████| 8/8 [00:01<00:00,  4.08it/s, loss=2.720423, accuracy=0.464286]\n",
      "EPOCH [VALID] 6/15: 100%|██████████| 2/2 [00:00<00:00, 17.77it/s, loss=5.546233, accuracy=0.158730]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH [TRAIN] 7/15: 100%|██████████| 8/8 [00:02<00:00,  3.93it/s, loss=2.605749, accuracy=0.448413]\n",
      "EPOCH [VALID] 7/15: 100%|██████████| 2/2 [00:00<00:00, 18.13it/s, loss=5.807947, accuracy=0.142857]\n",
      "EPOCH [TRAIN] 8/15: 100%|██████████| 8/8 [00:02<00:00,  3.92it/s, loss=2.007280, accuracy=0.579365]\n",
      "EPOCH [VALID] 8/15: 100%|██████████| 2/2 [00:00<00:00, 17.82it/s, loss=5.192978, accuracy=0.190476]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH [TRAIN] 9/15: 100%|██████████| 8/8 [00:02<00:00,  3.85it/s, loss=1.773937, accuracy=0.595238]\n",
      "EPOCH [VALID] 9/15: 100%|██████████| 2/2 [00:00<00:00, 15.79it/s, loss=5.238053, accuracy=0.222222]\n",
      "EPOCH [TRAIN] 10/15: 100%|██████████| 8/8 [00:01<00:00,  4.03it/s, loss=1.319313, accuracy=0.634921]\n",
      "EPOCH [VALID] 10/15: 100%|██████████| 2/2 [00:00<00:00, 18.02it/s, loss=5.482405, accuracy=0.238095]\n",
      "EPOCH [TRAIN] 11/15: 100%|██████████| 8/8 [00:02<00:00,  3.85it/s, loss=1.419916, accuracy=0.623016]\n",
      "EPOCH [VALID] 11/15: 100%|██████████| 2/2 [00:00<00:00, 15.53it/s, loss=7.298657, accuracy=0.190476]\n",
      "EPOCH [TRAIN] 12/15: 100%|██████████| 8/8 [00:02<00:00,  3.66it/s, loss=0.995307, accuracy=0.722222]\n",
      "EPOCH [VALID] 12/15: 100%|██████████| 2/2 [00:00<00:00, 17.88it/s, loss=6.388279, accuracy=0.206349]\n",
      "EPOCH [TRAIN] 13/15: 100%|██████████| 8/8 [00:02<00:00,  3.95it/s, loss=0.931632, accuracy=0.730159]\n",
      "EPOCH [VALID] 13/15: 100%|██████████| 2/2 [00:00<00:00, 17.44it/s, loss=5.801584, accuracy=0.174603]\n",
      "EPOCH [TRAIN] 14/15: 100%|██████████| 8/8 [00:02<00:00,  3.87it/s, loss=1.107262, accuracy=0.726190]\n",
      "EPOCH [VALID] 14/15: 100%|██████████| 2/2 [00:00<00:00, 16.71it/s, loss=5.256903, accuracy=0.206349]\n",
      "EPOCH [TRAIN] 15/15: 100%|██████████| 8/8 [00:02<00:00,  3.84it/s, loss=0.829540, accuracy=0.757937]\n",
      "EPOCH [VALID] 15/15: 100%|██████████| 2/2 [00:00<00:00, 16.92it/s, loss=5.110965, accuracy=0.269841]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train_fn(model, trainloader, optimizer, epoch)\n",
    "    valid_loss, valid_acc = eval_fn(model, validloader, epoch)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        torch.save(model.state_dict(), 'best_weights.pt')\n",
    "        print(\"Saved best weights\")\n",
    "        best_valid_loss = valid_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba0b547f-6c39-4e98-97cb-a20f4143af17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load best weights\n",
    "model.load_state_dict(torch.load('best_weights.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f568241-4c73-4d8e-b950-55a1ac0006f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "def predict(model, dataloader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            logits = model(images)\n",
    "            _, predicted = logits.max(1)\n",
    "\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return predictions, true_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e53793e8-07b7-4f30-b6db-bc05c3d3abd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "def predict(model, dataloader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            logits = model(images)\n",
    "            _, predicted = logits.max(1)\n",
    "\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return predictions, true_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33ecf076-9263-4aa2-82de-59ef0830feeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.33      0.32         9\n",
      "           1       0.25      0.09      0.13        11\n",
      "           2       0.11      0.12      0.12         8\n",
      "           3       0.33      0.22      0.27         9\n",
      "           4       0.30      0.33      0.32         9\n",
      "           5       0.20      0.40      0.27         5\n",
      "           6       0.36      0.42      0.38        12\n",
      "\n",
      "    accuracy                           0.27        63\n",
      "   macro avg       0.26      0.27      0.26        63\n",
      "weighted avg       0.27      0.27      0.26        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on validation set\n",
    "val_predictions, val_true_labels = predict(model, validloader)\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(val_true_labels, val_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083b2fe8-9795-4310-a505-a26558ef66db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Import the necessary components for the model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms as T\n",
    "import timm\n",
    "from torch import nn\n",
    "\n",
    "# Function to preprocess the test image\n",
    "def preprocess_image(file_path):\n",
    "    # Load the image\n",
    "    image = Image.open(file_path)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    image_gray = image.convert('L')\n",
    "    \n",
    "    # Resize to (48, 48)\n",
    "    image_resized = image_gray.resize((48, 48))\n",
    "    \n",
    "    # Convert to RGB\n",
    "    image_rgb = Image.new(\"RGB\", image_resized.size)\n",
    "    image_rgb.paste(image_resized)\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    image_np = np.array(image_rgb)\n",
    "    \n",
    "    # Convert to torch tensor and normalize\n",
    "    image_tensor = torch.tensor(image_np, dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
    "    \n",
    "    # Expand dimensions to make it a batch of size 1\n",
    "    image_tensor = image_tensor.unsqueeze(0)\n",
    "    \n",
    "    return image_tensor\n",
    "\n",
    "\n",
    "# Function to make predictions\n",
    "def predict_image(model, image_tensor):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(image_tensor)\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "    return predicted.item()\n",
    "    \n",
    "# Function to handle button click event\n",
    "def open_test_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        # Preprocess the image\n",
    "        image_tensor = preprocess_image(file_path)\n",
    "        \n",
    "        # Display the image\n",
    "        display_image(file_path)\n",
    "        \n",
    "        # Make prediction\n",
    "        predicted_class = predict_image(model, image_tensor)\n",
    "        \n",
    "        # Display result on Tkinter window\n",
    "        result_label.config(text=f\"Predicted Class: {class_names[predicted_class]}\")\n",
    "\n",
    "# Function to display the selected image on canvas\n",
    "def display_image(file_path):\n",
    "    # Open the image\n",
    "    image = Image.open(file_path)\n",
    "    \n",
    "    # Resize the image to fit canvas\n",
    "    image.thumbnail((200, 200))\n",
    "    \n",
    "    # Convert the image to PhotoImage format\n",
    "    photo = ImageTk.PhotoImage(image)\n",
    "    \n",
    "    # Display the image on canvas\n",
    "    canvas.create_image(0, 0, anchor=tk.NW, image=photo)\n",
    "    canvas.image = photo  # Keep a reference to avoid garbage collection\n",
    "\n",
    "# Load the trained model and class names\n",
    "MODEL_NAME = 'efficientnet_b0'\n",
    "NUM_CLASSES = 7\n",
    "model = DepressionModel(num_classes=NUM_CLASSES)\n",
    "model.load_state_dict(torch.load('best_weights.pt'))\n",
    "model.eval()\n",
    "\n",
    "# Load class names\n",
    "class_names = trainset.classes\n",
    "\n",
    "# Create Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Emotion Detection\")\n",
    "root.geometry(\"600x400\")\n",
    "\n",
    "# Configure the background color to black\n",
    "root.configure(bg=\"black\")\n",
    "\n",
    "\n",
    "# Create button to select test image\n",
    "button = tk.Button(root, text=\"Select Test Image\", command=open_test_image, bg=\"green\", fg=\"white\")\n",
    "button.pack(pady=20)\n",
    "\n",
    "# Canvas to display the selected image\n",
    "canvas = tk.Canvas(root, width=200, height=200, bg=\"black\", highlightthickness=0)\n",
    "canvas.pack()\n",
    "\n",
    "# Label to display result\n",
    "result_label = tk.Label(root, text=\"\", bg=\"black\", fg=\"White\")\n",
    "result_label.pack()\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9809b006-9b64-43c8-af14-fee687016625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
